#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è‚¡ç¥¨èµ„è®¯çˆ¬å–åŠŸèƒ½
"""

import sys
import os
import json
from EastMoneyStockNews import EastMoneyStockNews

def test_stock_news():
    """æµ‹è¯•è‚¡ç¥¨èµ„è®¯çˆ¬å–"""
    
    # è®¾ç½®DeepSeek APIå¯†é’¥
    deepseek_api_key = "sk-2c60a0afb4004678be7c5703e940d360"  # ä»é…ç½®æ–‡ä»¶è·å–
    
    # æµ‹è¯•è‚¡ç¥¨ä»£ç 
    stock_code = "688333"  # é“‚åŠ›ç‰¹
    
    try:
        print(f"å¼€å§‹æµ‹è¯•è‚¡ç¥¨ {stock_code} çš„èµ„è®¯çˆ¬å–...")
        
        # åˆ›å»ºçˆ¬å–å™¨
        news_crawler = EastMoneyStockNews(deepseek_api_key)
        
        # è·å–åŸå§‹æ•°æ®
        print("1. è·å–åŸå§‹èµ„è®¯æ•°æ®...")
        raw_data = news_crawler.get_stock_news_data(stock_code)
        
        if not raw_data:
            print("âŒ è·å–è‚¡ç¥¨èµ„è®¯æ•°æ®å¤±è´¥")
            return
        
        print(f"âœ… è·å–æˆåŠŸ:")
        print(f"   - èµ„è®¯: {len(raw_data.get('news', []))} æ¡")
        print(f"   - å…¬å‘Š: {len(raw_data.get('notices', []))} æ¡")
        print(f"   - ç ”æŠ¥: {len(raw_data.get('reports', []))} æ¡")
        
        # æ˜¾ç¤ºå‰å‡ æ¡èµ„è®¯
        if raw_data.get('news'):
            print("\nğŸ“° å‰3æ¡èµ„è®¯:")
            for i, news in enumerate(raw_data['news'][:3]):
                print(f"   {i+1}. {news['title']} ({news['date']})")
                print(f"      é“¾æ¥: {news['link']}")
        
        # è¿‡æ»¤æœ€è¿‘ä¸€å‘¨çš„æ•°æ®
        print("\n2. è¿‡æ»¤æœ€è¿‘ä¸€å‘¨çš„æ•°æ®...")
        filtered_data = news_crawler.filter_recent_week(raw_data)
        
        print(f"âœ… è¿‡æ»¤å®Œæˆ:")
        print(f"   - èµ„è®¯: {len(filtered_data.get('news', []))} æ¡")
        print(f"   - å…¬å‘Š: {len(filtered_data.get('notices', []))} æ¡")
        print(f"   - ç ”æŠ¥: {len(filtered_data.get('reports', []))} æ¡")
        
        # æµ‹è¯•æ–°é—»å†…å®¹è·å–
        if filtered_data.get('news'):
            print("\n3. æµ‹è¯•æ–°é—»å†…å®¹è·å–...")
            test_news = filtered_data['news'][0]
            print(f"æµ‹è¯•èµ„è®¯: {test_news['title']}")
            
            content = news_crawler.get_news_content(test_news['link'])
            if content:
                print(f"âœ… å†…å®¹è·å–æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"å†…å®¹é¢„è§ˆ: {content[:200]}...")
            else:
                print("âŒ å†…å®¹è·å–å¤±è´¥")
        
        # æµ‹è¯•æƒ…æ„Ÿåˆ†æ
        if filtered_data.get('news'):
            print("\n4. æµ‹è¯•æƒ…æ„Ÿåˆ†æ...")
            test_news = filtered_data['news'][0]
            print(f"åˆ†æèµ„è®¯: {test_news['title']}")
            
            # è·å–å†…å®¹
            content = news_crawler.get_news_content(test_news['link'])
            if content:
                # æƒ…æ„Ÿåˆ†æ
                sentiment = news_crawler.analyze_sentiment(content, test_news['title'])
                print(f"âœ… æƒ…æ„Ÿåˆ†æå®Œæˆ:")
                print(f"   - æƒ…æ„Ÿå€¾å‘: {sentiment.get('sentiment', 'unknown')}")
                print(f"   - æƒ…æ„Ÿå¼ºåº¦: {sentiment.get('score', 0)}/10")
                print(f"   - ç½®ä¿¡åº¦: {sentiment.get('confidence', 0)}%")
                print(f"   - åˆ†æç†ç”±: {sentiment.get('reason', 'N/A')}")
            else:
                print("âŒ æ— æ³•è·å–å†…å®¹ï¼Œè·³è¿‡æƒ…æ„Ÿåˆ†æ")
        
        print("\nâœ… æµ‹è¯•å®Œæˆ!")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = f"stock_news_{stock_code}_test.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(filtered_data, f, ensure_ascii=False, indent=2)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_stock_news()
